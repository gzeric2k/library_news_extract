# NewsBank 抓取器配置文件
# 复制此文件为 .env 并根据需要修改

# ============================================================
# 自动登录配置
# 警告：此文件包含敏感信息，请妥善保管！
# ============================================================

# 登录方式选择
# 可选值: "library_member" 或 "public_library"
LOGIN_TYPE=public_library

# 方式1: Public Library 登录（推荐，更简单）
# 使用图书馆卡号登录
PUBLIC_LIBRARY_CARD=your_library_card_number_here

# 方式2: Library Member 登录（通过SSO）
# 注意：此方式需要处理iframe，可能不稳定
LIBRARY_MEMBER_USERNAME=your_username_here
LIBRARY_MEMBER_PASSWORD=your_password_here

# 登录超时时间（秒）
LOGIN_TIMEOUT=120

# ============================================================
# 基础配置
SCRAPER_APP_NAME=NewsBank Scraper
SCRAPER_DEBUG=false

# Playwright 配置
SCRAPER_HEADLESS=true
SCRAPER_BROWSER_TYPE=chromium
SCRAPER_MAX_CONCURRENT_PAGES=5
SCRAPER_PAGE_TIMEOUT=30000

# 数据库配置
SCRAPER_DATABASE_PATH=newsbank.db
SCRAPER_MAX_DB_CONNECTIONS=5

# 代理配置
SCRAPER_USE_PROXY=false
# SCRAPER_PROXY_URL=http://proxy.example.com:8080

# 日志配置
SCRAPER_LOG_LEVEL=INFO

# 重试配置
SCRAPER_MAX_RETRIES=3
SCRAPER_RETRY_WAIT_BASE=1

# 请求配置
SCRAPER_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
SCRAPER_REQUEST_TIMEOUT=10000

# ============================================================
# AI智能筛选配置 (用于 newsbank_ai_downloader.py)
# ============================================================

# CLI Proxy API 配置（本地模型）
# 启用后，将使用本地 cli-proxy-api.exe 提供的模型，无需联网API
# 适用于本地部署的AI模型（如通过 LM Studio、Ollama、llama.cpp 等运行）
CLI_PROXY_ENABLED=false
CLI_PROXY_URL=http://localhost:8080/v1
CLI_PROXY_MODEL=local-model
CLI_PROXY_TIMEOUT=60

# NVIDIA API Key (推荐，当 CLI_PROXY_ENABLED=false 时使用)
# 获取地址: https://build.nvidia.com/explore/discover
# 格式: nvapi-xxxxxxxxxxxxxxxxxxxxxxxx
NVIDIA_API_KEY=nvapi-your-nvidia-api-key-here

# OpenAI API Key (可选)
# 获取地址: https://platform.openai.com/api-keys
# 格式: sk-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_API_KEY=sk-your-openai-api-key-here

# LLM提供商选择
# 可选值: "nvidia", "openai", "cli-proxy", "auto"
# "auto" 会根据API key前缀或配置自动检测
# 注意: 当 CLI_PROXY_ENABLED=true 时，此设置会被忽略，强制使用 cli-proxy
LLM_PROVIDER=auto

# LLM模型选择 (NVIDIA NIM)
# 推荐模型:
#   - z-ai/glm4.7 (默认，中文理解好)
#   - mistralai/mistral-large-3-675b-instruct-2512
#   - qwen/qwen3-235b-a22b
LLM_MODEL=z-ai/glm4.7

# 相关性阈值 (0.0 - 1.0)
# 越高 = 越严格，只下载最相关文章
# 越低 = 越宽松，下载更多文章
RELEVANCE_THRESHOLD=0.4
